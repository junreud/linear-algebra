# ğŸš€ ì™„ë²½í•œ ì„¤ì¹˜ ë° ì‹¤í–‰ ê°€ì´ë“œ

## ëª©ì°¨
1. [ì‚¬ì „ ìš”êµ¬ì‚¬í•­](#ì‚¬ì „-ìš”êµ¬ì‚¬í•­)
2. [ë‹¨ê³„ë³„ ì„¤ì¹˜](#ë‹¨ê³„ë³„-ì„¤ì¹˜)
3. [ì‹¤í–‰ ê°€ì´ë“œ](#ì‹¤í–‰-ê°€ì´ë“œ)
4. [ê²°ê³¼ í™•ì¸](#ê²°ê³¼-í™•ì¸)
5. [ë¬¸ì œí•´ê²°](#ë¬¸ì œí•´ê²°)

## ì‚¬ì „ ìš”êµ¬ì‚¬í•­

### ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
- **ìš´ì˜ì²´ì œ**: macOS, Linux, Windows
- **Python**: 3.8 ì´ìƒ (3.9~3.11 ê¶Œì¥)
- **ë©”ëª¨ë¦¬**: ìµœì†Œ 4GB RAM (8GB ê¶Œì¥)
- **ì €ì¥ê³µê°„**: 2GB ì´ìƒ
- **GPU**: ì„ íƒì‚¬í•­ (CUDA ì§€ì› GPU ê¶Œì¥)

### Python ì„¤ì¹˜ í™•ì¸
```bash
# Python ë²„ì „ í™•ì¸
python3 --version  # Python 3.8+ ì´ì–´ì•¼ í•¨

# pip ì„¤ì¹˜ í™•ì¸
python3 -m pip --version
```

## ë‹¨ê³„ë³„ ì„¤ì¹˜

### Step 1: í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
```bash
# í„°ë¯¸ë„ì—ì„œ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /Users/gimjunseog/projects/linear-algebra/transformer_tutorial

# í˜„ì¬ ìœ„ì¹˜ í™•ì¸
pwd
ls -la  # main.py, requirements.txt ë“±ì´ ë³´ì—¬ì•¼ í•¨
```

### Step 2: Python ê°€ìƒí™˜ê²½ ìƒì„±
```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (transformer_envë¼ëŠ” ì´ë¦„ìœ¼ë¡œ)
python3 -m venv transformer_env

# ìƒì„± í™•ì¸
ls -la transformer_env/  # bin, lib, include í´ë”ê°€ ë³´ì—¬ì•¼ í•¨
```

### Step 3: ê°€ìƒí™˜ê²½ í™œì„±í™”
```bash
# macOS/Linuxì—ì„œ í™œì„±í™”
source transformer_env/bin/activate

# í™œì„±í™” í™•ì¸ - í”„ë¡¬í”„íŠ¸ê°€ (transformer_env)ë¡œ ì‹œì‘í•´ì•¼ í•¨
# ì˜ˆ: (transformer_env) user@computer:~/path$
```

**Windows ì‚¬ìš©ìì˜ ê²½ìš°:**
```cmd
# Windowsì—ì„œ í™œì„±í™”
transformer_env\Scripts\activate
```

### Step 4: pip ì—…ê·¸ë ˆì´ë“œ
```bash
# pipë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip

# ë²„ì „ í™•ì¸
pip --version
```

### Step 5: íŒ¨í‚¤ì§€ ì„¤ì¹˜

#### ë°©ë²• A: requirements.txt ì¼ê´„ ì„¤ì¹˜ (ê¶Œì¥)
```bash
# ëª¨ë“  íŒ¨í‚¤ì§€ í•œ ë²ˆì— ì„¤ì¹˜
pip install -r requirements.txt

# ì„¤ì¹˜ ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë‚˜ë©´ ë°©ë²• B ì‚¬ìš©
```

#### ë°©ë²• B: ë‹¨ê³„ë³„ ì„¤ì¹˜ (ë¬¸ì œ ë°œìƒì‹œ)
```bash
# 1. í•µì‹¬ íŒ¨í‚¤ì§€ë¶€í„° ì„¤ì¹˜
pip install torch>=2.0.0 torchvision>=0.15.0 torchaudio>=2.0.0

# 2. Transformers ê´€ë ¨
pip install transformers>=4.30.0 tokenizers>=0.13.0

# 3. ë°ì´í„° ì²˜ë¦¬
pip install numpy>=1.24.0 pandas>=2.0.0

# 4. ì‹œê°í™”
pip install matplotlib>=3.7.0 seaborn>=0.12.0

# 5. ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°
pip install tqdm>=4.65.0 scikit-learn>=1.3.0

# 6. ì„ íƒì‚¬í•­ (ê³ ê¸‰ ê¸°ëŠ¥)
pip install datasets>=2.12.0 accelerate>=0.20.0
pip install tensorboard>=2.13.0  # ë¡œê¹…ìš©
pip install wandb>=0.15.0        # ì‹¤í—˜ ì¶”ì ìš© (ì„ íƒ)
```

### Step 6: ì„¤ì¹˜ í™•ì¸
```bash
# í•µì‹¬ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
python -c "
import torch
import transformers
import numpy as np
import matplotlib.pyplot as plt
print('âœ… ëª¨ë“  í•µì‹¬ íŒ¨í‚¤ì§€ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!')
print(f'PyTorch ë²„ì „: {torch.__version__}')
print(f'Transformers ë²„ì „: {transformers.__version__}')
print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')
"
```

ì„±ê³µì‹œ ì¶œë ¥ ì˜ˆì‹œ:
```
âœ… ëª¨ë“  í•µì‹¬ íŒ¨í‚¤ì§€ê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì¹˜ë˜ì—ˆìŠµë‹ˆë‹¤!
PyTorch ë²„ì „: 2.0.1
Transformers ë²„ì „: 4.30.2
CUDA ì‚¬ìš© ê°€ëŠ¥: True
```

## ì‹¤í–‰ ê°€ì´ë“œ

### ì²« ì‹¤í–‰ (ì¶”ì²œ)

#### ğŸ¯ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (1-2ë¶„)
```bash
# ì„¤ì¹˜ê°€ ì œëŒ€ë¡œ ë˜ì—ˆëŠ”ì§€ ë¹ ë¥¸ í™•ì¸
python main.py --version test
```

#### ğŸ” ê¸°ë³¸ ì‹¤í–‰ (5-10ë¶„)
```bash
# ë‘ ë²„ì „ ëª¨ë‘ ê°„ë‹¨íˆ ì‹¤í–‰
python main.py --version both --epochs 2 --train_size 500 --eval_size 100
```

ì¶œë ¥ ì˜ˆì‹œ:
```
ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤: cuda:0
=== PYTORCH ìˆœì • TRANSFORMER ì‹¤í–‰ ===
Creating datasets...
Train batches: 32
Val batches: 7
Creating model...
Starting training for 2 epochs...
```

### ìƒì„¸ ë¶„ì„ ì‹¤í–‰

#### ğŸ“š PyTorch ë²„ì „ (êµìœ¡ìš©)
```bash
# ë‚´ë¶€ ë™ì‘ì„ ìƒì„¸íˆ ë³¼ ìˆ˜ ìˆëŠ” ë””ë²„ê·¸ ëª¨ë“œ
python main.py --version pytorch --epochs 3 --debug --visualize \
    --batch_size 8 --train_size 1000 --eval_size 200
```

ì‹¤í–‰ ì¤‘ ì¶œë ¥ ì˜ˆì‹œ:
```
=== Multi-Head Attention Forward Pass ===
Input shapes - Q: torch.Size([8, 10, 256]), K: torch.Size([8, 10, 256])
1. Linear Transformations:
Q after W_q: torch.Size([8, 10, 256]), mean: 0.0234, std: 0.8901
2. Reshape for Multi-Head:
Q reshaped: torch.Size([8, 8, 10, 32])
3. Attention Output: torch.Size([8, 8, 10, 32])
```

#### ğŸ­ Hugging Face ë²„ì „ (ì‹¤ë¬´ìš©)
```bash
# ì‹¤ë¬´ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ì‹ì˜ êµ¬í˜„
python main.py --version huggingface --epochs 5 --track_internals \
    --batch_size 16 --train_size 2000 --eval_size 500
```

#### ğŸ“Š WandB ë¡œê¹… í¬í•¨ (ê³ ê¸‰)
```bash
# ì‹¤í—˜ ì¶”ì  ë„êµ¬ì™€ í•¨ê»˜ ì‹¤í–‰
pip install wandb  # ì•„ì§ ì„¤ì¹˜ ì•ˆí–ˆë‹¤ë©´
wandb login        # ì²˜ìŒ í•œ ë²ˆë§Œ (ì›¹ë¸Œë¼ìš°ì €ì—ì„œ API í‚¤ ì…ë ¥)

python main.py --version huggingface --epochs 10 --track_internals \
    --wandb --wandb_project my-transformer-experiment
```

### ë§¤ê°œë³€ìˆ˜ ì„¤ëª…

| ë§¤ê°œë³€ìˆ˜ | ì„¤ëª… | ê¸°ë³¸ê°’ | ì˜ˆì‹œ |
|---------|------|--------|------|
| `--version` | ì‹¤í–‰í•  ë²„ì „ | `both` | `pytorch`, `huggingface`, `both` |
| `--epochs` | í•™ìŠµ ì—í­ ìˆ˜ | `5` | `--epochs 10` |
| `--batch_size` | ë°°ì¹˜ í¬ê¸° | `16` | `--batch_size 32` |
| `--hidden_size` | ëª¨ë¸ ì°¨ì› | `256` | `--hidden_size 512` |
| `--train_size` | í›ˆë ¨ ë°ì´í„° í¬ê¸° | `2000` | `--train_size 5000` |
| `--debug` | ìƒì„¸ ë¡œê·¸ ì¶œë ¥ | `False` | `--debug` |
| `--visualize` | ì‹œê°í™” ìƒì„± | `False` | `--visualize` |
| `--track_internals` | ë‚´ë¶€ ìƒíƒœ ì¶”ì  | `False` | `--track_internals` |

## ê²°ê³¼ í™•ì¸

### ì‹¤í–‰ ì™„ë£Œ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤

```
transformer_tutorial/
â”œâ”€â”€ results_pytorch/                 # PyTorch ë²„ì „ ê²°ê³¼
â”‚   â”œâ”€â”€ checkpoints/
â”‚   â”‚   â”œâ”€â”€ best_model.pt           # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”‚   â””â”€â”€ checkpoint_epoch_*.pt   # ì¤‘ê°„ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ training_curves.png     # í•™ìŠµ ê³¡ì„ 
â”‚   â”‚   â”œâ”€â”€ attention_plots/
â”‚   â”‚   â”‚   â””â”€â”€ attention_evolution.png  # Attention ë³€í™”
â”‚   â”‚   â””â”€â”€ qkv_evolution.png       # QKV ê°’ ë³€í™”
â”‚   â””â”€â”€ logs/                       # ìƒì„¸ ë¡œê·¸
â”œâ”€â”€ results_huggingface/            # Hugging Face ë²„ì „ ê²°ê³¼
â”‚   â”œâ”€â”€ pytorch_model.bin           # ì €ì¥ëœ ëª¨ë¸
â”‚   â”œâ”€â”€ config.json                 # ëª¨ë¸ ì„¤ì •
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”‚   â”œâ”€â”€ attention/
â”‚   â”‚   â”‚   â””â”€â”€ attention_step_*.png
â”‚   â”‚   â””â”€â”€ qkv/
â”‚   â”‚       â””â”€â”€ qkv_evolution.png
â”‚   â””â”€â”€ runs/                       # TensorBoard ë¡œê·¸
â””â”€â”€ sample_visualizations/           # ë¶„ì„ ë„êµ¬ ë°ëª¨ ê²°ê³¼
    â”œâ”€â”€ sample_attention_heatmap.png
    â”œâ”€â”€ sample_multihead_attention.png
    â””â”€â”€ sample_training_curves.png
```

### ê²°ê³¼ íŒŒì¼ í™•ì¸ ë°©ë²•

#### 1. ì‹œê°í™” ê²°ê³¼ í™•ì¸
```bash
# ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ í™•ì¸
ls -la results_*/visualizations/
open results_pytorch/visualizations/training_curves.png  # macOS
```

#### 2. í•™ìŠµ ë¡œê·¸ í™•ì¸
```bash
# í•™ìŠµ ê³¼ì • ë¡œê·¸ í™•ì¸
tail -n 20 results_pytorch/logs/training.log
```

#### 3. ëª¨ë¸ íŒŒì¼ í™•ì¸
```bash
# ì €ì¥ëœ ëª¨ë¸ í¬ê¸° í™•ì¸
ls -lh results_*/checkpoints/
ls -lh results_*/pytorch_model.bin
```

## ë¬¸ì œí•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

#### 1. ê°€ìƒí™˜ê²½ í™œì„±í™” ë¬¸ì œ
**ì¦ìƒ**: `(transformer_env)` í‘œì‹œê°€ ì•ˆ ë³´ì„
```bash
# í•´ê²°: ì „ì²´ ê²½ë¡œë¡œ í™œì„±í™”
source /Users/gimjunseog/projects/linear-algebra/transformer_tutorial/transformer_env/bin/activate

# í™•ì¸
echo $VIRTUAL_ENV  # ê²½ë¡œê°€ ë‚˜ì™€ì•¼ í•¨
which python       # transformer_env ë‚´ë¶€ pythonì´ì–´ì•¼ í•¨
```

#### 2. íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨
**ì¦ìƒ**: `pip install` ëª…ë ¹ì–´ ì‹¤íŒ¨
```bash
# í•´ê²° 1: pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip setuptools wheel

# í•´ê²° 2: ìºì‹œ ì‚­ì œ í›„ ì¬ì„¤ì¹˜
pip cache purge
pip install --no-cache-dir -r requirements.txt

# í•´ê²° 3: ê°œë³„ ì„¤ì¹˜
pip install torch  # í•˜ë‚˜ì”© ì„¤ì¹˜í•´ë³´ê¸°
```

#### 3. CUDA ê´€ë ¨ ì˜¤ë¥˜
**ì¦ìƒ**: GPU ê´€ë ¨ ì—ëŸ¬ ë©”ì‹œì§€
```bash
# í•´ê²°: CPU ëª¨ë“œë¡œ ì‹¤í–‰
python main.py --version pytorch --epochs 2 --batch_size 4

# GPU ìƒíƒœ í™•ì¸
python -c "import torch; print('CUDA:', torch.cuda.is_available())"
```

#### 4. ë©”ëª¨ë¦¬ ë¶€ì¡±
**ì¦ìƒ**: `CUDA out of memory` ë˜ëŠ” ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# í•´ê²°: ë°°ì¹˜ í¬ê¸°ì™€ ëª¨ë¸ í¬ê¸° ì¤„ì´ê¸°
python main.py --version pytorch --epochs 2 \
    --batch_size 4 --hidden_size 128 --train_size 300 --eval_size 50
```

#### 5. ì‹œê°í™” ì˜¤ë¥˜
**ì¦ìƒ**: matplotlib ê´€ë ¨ ì—ëŸ¬
```bash
# í•´ê²°: ë°±ì—”ë“œ ì„¤ì •
export MPLBACKEND=Agg  # GUI ì—†ëŠ” í™˜ê²½ìš©
python main.py --version pytorch --visualize

# ë˜ëŠ” X11 í¬ì›Œë”© (SSH ì‚¬ìš©ì‹œ)
ssh -X username@hostname
```

#### 6. ì„í¬íŠ¸ ì—ëŸ¬
**ì¦ìƒ**: `ModuleNotFoundError`
```bash
# í•´ê²° 1: ê°€ìƒí™˜ê²½ í™•ì¸
which python  # transformer_env ë‚´ë¶€ì—¬ì•¼ í•¨

# í•´ê²° 2: íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜
pip uninstall torch transformers
pip install torch transformers

# í•´ê²° 3: Python path í™•ì¸
python -c "import sys; print(sys.path)"
```

### ì„±ëŠ¥ íŠœë‹

#### ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì •
```bash
# ìµœì†Œ ì„¤ì •ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python main.py --version pytorch --epochs 1 \
    --batch_size 4 --train_size 200 --eval_size 50 \
    --hidden_size 128 --num_layers 2
```

#### ê³ ì„±ëŠ¥ ì‹¤í–‰ì„ ìœ„í•œ ì„¤ì •
```bash
# GPUê°€ ìˆëŠ” ê²½ìš° ìµœëŒ€ ì„±ëŠ¥
python main.py --version huggingface --epochs 20 \
    --batch_size 64 --train_size 10000 --eval_size 2000 \
    --hidden_size 512 --num_layers 8 --track_internals
```

## ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ ì „ í™•ì¸:
- [ ] Python 3.8+ ì„¤ì¹˜ë¨
- [ ] ê°€ìƒí™˜ê²½ ìƒì„±ë¨ (`transformer_env/` í´ë” ì¡´ì¬)
- [ ] ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨ (í”„ë¡¬í”„íŠ¸ì— `(transformer_env)` í‘œì‹œ)
- [ ] íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨ (`pip list | grep torch` ê²°ê³¼ ìˆìŒ)
- [ ] í˜„ì¬ ë””ë ‰í† ë¦¬ê°€ `transformer_tutorial/`
- [ ] `main.py` íŒŒì¼ ì¡´ì¬í•¨

ì²« ì‹¤í–‰ ëª…ë ¹ì–´:
```bash
# âœ… ì´ ëª…ë ¹ì–´ë¡œ ì‹œì‘í•˜ì„¸ìš”!
python main.py --version both --epochs 2 --train_size 500 --eval_size 100
```

ì„±ê³µì ì¸ ì‹¤í–‰ì˜ ì‹ í˜¸:
- í„°ë¯¸ë„ì— `ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤: cpu` ë˜ëŠ” `cuda` ì¶œë ¥
- `Creating datasets...` ë©”ì‹œì§€ ì¶œë ¥
- `results_*/` í´ë” ìƒì„±
- ì—í­ë³„ loss ê°’ ì¶œë ¥

## ê°€ìƒí™˜ê²½ ê´€ë¦¬

### ê°€ìƒí™˜ê²½ ì¢…ë£Œ
```bash
# ì‘ì—… ì™„ë£Œ í›„ ê°€ìƒí™˜ê²½ ë¹„í™œì„±í™”
deactivate
```

### ê°€ìƒí™˜ê²½ ì¬ì‹œì‘
```bash
# ë‹¤ìŒ ì‘ì—…ì‹œ ê°€ìƒí™˜ê²½ ë‹¤ì‹œ í™œì„±í™”
cd /Users/gimjunseog/projects/linear-algebra/transformer_tutorial
source transformer_env/bin/activate
python main.py --version test  # ë¹ ë¥¸ ë™ì‘ í™•ì¸
```

### ê°€ìƒí™˜ê²½ ì‚­ì œ (í•„ìš”ì‹œ)
```bash
# ê°€ìƒí™˜ê²½ ì™„ì „ ì‚­ì œ í›„ ì¬ìƒì„±
deactivate
rm -rf transformer_env
python3 -m venv transformer_env
source transformer_env/bin/activate
pip install -r requirements.txt
```

ì´ì œ ì™„ë²½í•˜ê²Œ ì„¤ì¹˜í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€