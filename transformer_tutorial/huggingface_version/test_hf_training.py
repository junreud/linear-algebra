"""
Encoder-Decoder HuggingFace ë°ì´í„°ì…‹ í›ˆë ¨ í…ŒìŠ¤íŠ¸

ì‹¤ì œ ë²ˆì—­ ë°ì´í„°ì…‹ìœ¼ë¡œ ëª¨ë¸ì„ í›ˆë ¨í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.
"""

import sys
import os

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from train_encoder_decoder_hf import main, HuggingFaceTranslationDataset
import torch
from transformers import AutoTokenizer


def test_dataset_loading():
    """ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª HuggingFace ë²ˆì—­ ë°ì´í„°ì…‹ í…ŒìŠ¤íŠ¸")
    
    try:
        # ì˜ì–´-í•œêµ­ì–´ ë„ì„œ ë²ˆì—­ ë°ì´í„°
        print("\n1. OPUS Books (EN-KO) í…ŒìŠ¤íŠ¸...")
        dataset = HuggingFaceTranslationDataset(
            dataset_name="opus_books",
            src_lang="en",
            tgt_lang="ko",
            num_samples=100,
            split="train"
        )
        print(f"âœ… OPUS Books ë¡œë“œ ì„±ê³µ: {len(dataset)}ê°œ ìƒ˜í”Œ")
        
        # ìƒ˜í”Œ í™•ì¸
        sample = dataset[0]
        print(f"ğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
        print(f"   ì†ŒìŠ¤: {sample['src_text']}")
        print(f"   íƒ€ê²Ÿ: {sample['tgt_text']}")
        print(f"   Input IDs í˜•íƒœ: {sample['input_ids'].shape}")
        
    except Exception as e:
        print(f"âŒ OPUS Books ì‹¤íŒ¨: {e}")
        
        # ëŒ€ì•ˆ: ì˜ì–´-í”„ë‘ìŠ¤ì–´
        try:
            print("\nëŒ€ì•ˆ: OPUS Books (EN-FR) í…ŒìŠ¤íŠ¸...")
            dataset = HuggingFaceTranslationDataset(
                dataset_name="opus_books",
                src_lang="en",
                tgt_lang="fr",
                num_samples=100,
                split="train"
            )
            print(f"âœ… OPUS Books (EN-FR) ë¡œë“œ ì„±ê³µ: {len(dataset)}ê°œ ìƒ˜í”Œ")
            
            sample = dataset[0]
            print(f"ğŸ“ ìƒ˜í”Œ ë°ì´í„°:")
            print(f"   ì†ŒìŠ¤: {sample['src_text']}")
            print(f"   íƒ€ê²Ÿ: {sample['tgt_text']}")
            
        except Exception as e2:
            print(f"âŒ OPUS Books (EN-FR) ì‹¤íŒ¨: {e2}")
            
            # ë‹¤ë¥¸ ë°ì´í„°ì…‹ ì‹œë„
            try:
                print("\nëŒ€ì•ˆ: OPUS-100 (EN-FR) í…ŒìŠ¤íŠ¸...")
                dataset = HuggingFaceTranslationDataset(
                    dataset_name="opus100",
                    src_lang="en",
                    tgt_lang="fr",
                    num_samples=100,
                    split="train"
                )
                print(f"âœ… OPUS-100 ë¡œë“œ ì„±ê³µ: {len(dataset)}ê°œ ìƒ˜í”Œ")
                
            except Exception as e3:
                print(f"âŒ ëª¨ë“  ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨")
                print(f"ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”")


def test_quick_training():
    """ë¹ ë¥¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ (ì‘ì€ ë°ì´í„°ì…‹)"""
    print("\nğŸš€ ë¹ ë¥¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸")
    
    device = torch.device('mps' if torch.backends.mps.is_available() 
                         else 'cuda' if torch.cuda.is_available() 
                         else 'cpu')
    print(f"ğŸ–¥ï¸  ë””ë°”ì´ìŠ¤: {device}")
    
    # ê°€ìƒìœ¼ë¡œ ëª…ë ¹ì¤„ ì¸ìˆ˜ ì„¤ì •
    import argparse
    import sys
    
    # ê¸°ì¡´ argv ë°±ì—…
    original_argv = sys.argv
    
    try:
        # í…ŒìŠ¤íŠ¸ìš© ëª…ë ¹ì¤„ ì¸ìˆ˜
        sys.argv = [
            'train_encoder_decoder_hf.py',
            '--dataset', 'opus_books',
            '--src_lang', 'en',
            '--tgt_lang', 'fr',  # í•œêµ­ì–´ë³´ë‹¤ í”„ë‘ìŠ¤ì–´ê°€ ë” ë§ì€ ë°ì´í„° ë³´ìœ 
            '--num_samples', '200',  # ë§¤ìš° ì‘ì€ ë°ì´í„°ì…‹
            '--epochs', '1',
            '--batch_size', '2',
            '--gradient_accumulation_steps', '2',
            '--hidden_size', '128',  # ì‘ì€ ëª¨ë¸
            '--encoder_layers', '2',
            '--decoder_layers', '2',
            '--attention_heads', '4',
            '--save_dir', 'test_checkpoints_hf'
        ]
        
        print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì„¤ì •:")
        print("   - ë°ì´í„°ì…‹: OPUS Books (EN-FR)")
        print("   - ìƒ˜í”Œ ìˆ˜: 200ê°œ")
        print("   - ì—í¬í¬: 1")
        print("   - ëª¨ë¸ í¬ê¸°: ì‘ìŒ (128 hidden)")
        
        # ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
        main()
        
    except Exception as e:
        print(f"âŒ í›ˆë ¨ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print(f"ğŸ’¡ ì´ëŠ” ì •ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë°ì´í„°ì…‹ ì ‘ê·¼ ì œí•œ ë“±)")
        
    finally:
        # argv ë³µì›
        sys.argv = original_argv


def usage_examples():
    """ì‚¬ìš© ì˜ˆì‹œ"""
    print("\nğŸ“š ì‚¬ìš© ì˜ˆì‹œ:")
    print("\n1. ì˜ì–´-í•œêµ­ì–´ ë²ˆì—­ (OPUS Books):")
    print("   python train_encoder_decoder_hf.py \\")
    print("       --dataset opus_books \\")
    print("       --src_lang en --tgt_lang ko \\")
    print("       --epochs 5 --num_samples 5000")
    
    print("\n2. ì˜ì–´-í”„ë‘ìŠ¤ì–´ ë²ˆì—­ (WMT16):")
    print("   python train_encoder_decoder_hf.py \\")
    print("       --dataset wmt16 \\")
    print("       --src_lang en --tgt_lang fr \\")
    print("       --epochs 10 --batch_size 8")
    
    print("\n3. ë‹¤êµ­ì–´ ë²ˆì—­ (OPUS-100):")
    print("   python train_encoder_decoder_hf.py \\")
    print("       --dataset opus100 \\")
    print("       --src_lang en --tgt_lang de \\")
    print("       --hidden_size 512 --encoder_layers 6")
    
    print("\n4. ì‘ì€ ëª¨ë¸ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸:")
    print("   python train_encoder_decoder_hf.py \\")
    print("       --dataset kde4 \\")
    print("       --src_lang en --tgt_lang fr \\")
    print("       --num_samples 1000 --epochs 2 \\")
    print("       --hidden_size 128 --encoder_layers 2")


if __name__ == "__main__":
    print("ğŸ§ª Encoder-Decoder HuggingFace ë°ì´í„°ì…‹ í›ˆë ¨ í…ŒìŠ¤íŠ¸\n")
    
    # ë°ì´í„°ì…‹ ë¡œë”© í…ŒìŠ¤íŠ¸
    test_dataset_loading()
    
    # ì‚¬ìš© ì˜ˆì‹œ
    usage_examples()
    
    # ë¹ ë¥¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
    print(f"\nâ“ ë¹ ë¥¸ í›ˆë ¨ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    choice = input().lower().strip()
    
    if choice in ['y', 'yes', 'ì˜ˆ']:
        test_quick_training()
    else:
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("ğŸ’¡ ì‹¤ì œ í›ˆë ¨ì„ ìœ„í•´ì„œëŠ” train_encoder_decoder_hf.pyë¥¼ ì§ì ‘ ì‹¤í–‰í•˜ì„¸ìš”.")